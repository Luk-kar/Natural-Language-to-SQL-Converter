# üîéü§ñ Natural Language to SQL Converter

This repository offers an open-source environment for experimenting with LLM-powered database search. It includes a server setup for running different model, sample code for integrating them into applications and Postgres service as a database.

For demonstration purposes the [pokemon dataset](https://github.com/lgreski/pokemonData/blob/master/Pokemon.csv) was used.

Key features of the application include:
- Querying the database using natural language input
- Generating visualizations by the LLM from predefined plot types
- Automatic fallback logic to select relevant plot when the LLM failed
- LLM-generated tooltips explaining different parts of the SQL query
- Natural language description of the database generated by the LLM
<br><br>

![generated query. its results and tooltip](doc/images/001-overall-usage.png)
<br>

![generated plot](doc/images/002-plot.png)

## üóÇÔ∏è Project Structure

![services communication](doc/images/services-communication.png)

Here is the rewritten section based on the image you provided and the issues in the original:

---

### üìö Key Libraries

**LLM Host:**

- [**`flask`**](https://flask.palletsprojects.com/)
  
  _Lightweight web framework to handle HTTP requests and route interactions with the LLM._

- [**`gunicorn`**](https://gunicorn.org/)
  
  _WSGI HTTP server used to serve the Flask app in a production environment._

**Prompt Execution:**

- [**`llama-cpp-python`**](https://github.com/abetlen/llama-cpp-python)
  
  _Python bindings for running LLaMA models locally for prompt execution._

**Plot Rendering:**

- [**`bokeh`**](https://docs.bokeh.org/en/latest/)
  
  _Interactive plotting library for rendering visualizations in the browser._

- [**`pandas`**](https://pandas.pydata.org/)
  
  _Data manipulation library used for preparing datasets before visualization._

- [**`scipy`**](https://scipy.org/)
  
  _Provides advanced math operations to support plot-related calculations._

- [**`squarify`**](https://github.com/laserson/squarify)
  
  _Used for generating treemap visualizations based on hierarchical data._

- [**`colorcet`**](https://colorcet.holoviz.org/)
  
  _Color palettes used to enhance plot aesthetics and clarity._

**Database Communication:**

- [**`psycopg2-binary`**](https://www.psycopg.org/docs/)
  
  _PostgreSQL adapter for Python used to send and retrieve data via SQL queries._


## üì¶ Requirements

See the:
- [`requirements.txt`](requirements.txt) for needed packages for llm backend.
- [`docker-compose.yml`](docker-compose.yml) for services.

## ‚öôÔ∏èüî® Installation and Usage
1. **Clone the repository**
    ```bash
    git clone https://github.com/your-username/nl2sql-converter.git
    cd nl2sql-converter
    ```
1. **Download the LLM model**:
    ```bash
    wget -O app/backend/models/ggml-model-Q4_K.gguf https://huggingface.co/NousResearch/Nous-Capybara-7B-V1-GGUF/resolve/e6263e5fabbdcd2d682364c66ecf54b65f25aa39/ggml-model-Q4_K.gguf?download=true
    ```
    or any other model like `DeepSeek-V3`, `Mistral` or `Nous Capybara`, etc.

1. **Configure environment variables**  
   Copy the example file and edit it with your credentials and model settings:  
   ```bash
   cp .env.example .env
   # Open .env in your editor and adjust DB_USER, DB_PASSWORD, LLM_MODEL_NAME, etc.
   ```
1. **Start services with Docker Compose**  
   ```bash
   docker-compose up --build -d
   ```
   - PostgreSQL will initialize the `pokemon` table and load the CSV dataset.  
   - The Flask‚ÄêGunicorn backend will be built and started on `0.0.0.0:${FLASK_RUN_PORT}`.
   - 
4. **Verify everything is running**  
   ```bash
   # List running containers
   docker ps
   # You should see:
   #   postgres_nl2sql   postgres:15     Up ...   5432/tcp
   #   backend_nl2sql    your-backend    Up ...   5000/tcp
   ```

5. **Access the application**  
   Open your browser and navigate to:  
   ```
   http://localhost:${FLASK_RUN_PORT}
   ```
## üîß Configuration

All settings are loaded from the `.env` file.
Keep n mind to provide the `FLASK_SECRET_KEY` when you have plans to set up in production.

## ‚úÖ Testing

To test, activate the environment and run tests:

```bash
pipenv shell
python -m unittest discover
```
---

## üí° Notes

- LLMs demand significant compute resources, ensure your hardware can handle intense inference workloads.  
- Treat this tool as an exploratory aid: models may hallucinate or lack up‚Äëto‚Äëdate context.
- It is not advices to give LLM agents any grants more than just read type.

## üß© Contributing
Treat this project just as start, there are many improvements that can implemented like:
- **Testing:** Add end‚Äëto‚Äëend and unit tests for the native JavaScript frontend.  
- **Frontend Frameworks:** Explore integrating React, Vue, or similar for better maintainability.  
- **Backend Optimization:** Profile and reduce CPU/memory usage during LLM inference and database queries.  
- **Production Hardening:** Improve security, error handling, and user experience for real‚Äëworld deployments.  
- **Streamlined Setup:** Automate and simplify installation, configuration, and deployment

## üìú License
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.